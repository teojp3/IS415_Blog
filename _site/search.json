{
  "articles": [
    {
      "path": "about.html",
      "title": "About this blog",
      "description": "I am Jun Peng, currently in my third year in the School of Computing & Information Systems at Singapore Management University.\n\nWelcome to my personal workspace! The content listed on the blog will mainly be related to Geospatial Analytics, a module I'm currently taking this semester.",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2021-09-06T19:09:52+08:00"
    },
    {
      "path": "index.html",
      "title": "My Workspace",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2021-09-06T19:09:39+08:00"
    },
    {
      "path": "take-home-exercise-1.html",
      "title": "Take Home Exercise 1",
      "description": "Analysing and Visualising Spatio-temporal Patterns of COVID-19 in DKI Jakarta, Indonesia.\n",
      "author": [
        {
          "name": "Teo Jun Peng",
          "url": "https://teojp3-is415.netlify.app/"
        }
      ],
      "date": "08-27-2021",
      "contents": "\r\n1. Introduction\r\nThis analysis aims to analyse and visualise spatio-temporal patterns of COVID-19 in DKI Jakarta, Indonesia. Out of 34 provinces in Indonesia, DKI Jakarta was the province affected most by the pandemic, with close to 24% of cumulative confirmed cases. However, the cumulative confirmed cases were not evenly distributed, therefore this analysis intends to unravel which sub-districts had the highest number of cases and how time has changed the overall distribution.\r\nTHE DATA\r\nFor this analysis, the following data are used:\r\nOpen Data Covid-19 Provinsi DKI Jakarta. This portal provides daily update of COVID-19 measures at both sub-district and district level. For the purpose of this analysis, data at the sub-district level is used. The datasets are in .CSV format, and monthly datasets from March 2020 to July 2021 will be used.\r\nIndonesia Geospatial. This portal provides a comprehensive collection of geospatial data mainly in ESRI shapefile format at different geographical levels. For the purpose of this analysis, the Shapefile (SHP) Batas Desa Provinsi DKI Jakarta provided at PODES 2019 geospatial layer is used.\r\n2. Setting up the environment\r\nR packages will be used for efficiency and a more comprehensive analysis, such as tidyverse and sf etc.\r\n\r\n\r\nload(\"THE1_workspace.Rdata\")\r\npackages = c('tidyverse', 'sf', 'readxl', 'readr', 'stringr', 'tmap')\r\nfor (p in packages)\r\n  {\r\n  if(!require(p, character.only = T))\r\n    {\r\n    install.packages(p)\r\n  }\r\n  library(p,character.only = T)\r\n}\r\n\r\n\r\n\r\n3. Data Wrangling\r\nImporting aspatial Data\r\nList.files helps to create a list from the imported data files. The files are also imported all at once using a pattern to match the file names, ensuring full efficiency as compared to importing the files individually. The R function lapply is also complementary for this process, as well as adding the file names as an additional column to the dataframes (So as to display the data by month later on).\r\n\r\n\r\nfile_list <- list.files(path = \"data/the1data/COVID-DATA\" , pattern = \"*.xlsx\",  full.names = T)\r\ndf_list <- lapply(seq_along(file_list), function(x) transform(read_xlsx(file_list[x]), MonthYear = file_list[x]))\r\n\r\n\r\n\r\nFrom here we then manually check through df_list to find which Meninggal column is the correct one for each file, for referencing the coalesce process later on in the next few steps (E.g. For February 2021, Meninggal…1 is the correct column to use since it is the Meninggal column with no NA values.) The inspection tells us that Meninggal…23 to Meninggal…25 is not used so we can skip those columns later on in the coalesce process.\r\n\r\n\r\ndf_list\r\n\r\n\r\n\r\nWe will now combine df_list into a real dataframe using Idlpy function from the plyr package.\r\n\r\n\r\nlibrary(plyr)\r\ndf <- ldply(df_list, data.frame)\r\n\r\n\r\n\r\nTo combine/integrate values from the various Meninggal columns, we will have to convert Meninggal…26 column’s data type so we can use coalesce function later on (because it originally is a chr type and chr type cannot combine with double type). July 2020 is using Meninggal…26 as the correct column, so we have to carry out the conversion.\r\n\r\n\r\ndf$Meninggal...26 = as.double(df$Meninggal...26)\r\n\r\ndf <- df %>%\r\n  na_if(\"N/A\")\r\n\r\n\r\n\r\nIn this step we aim to combine ID_KEL into one main column, since some of the files have different layouts. Coalesce is a function to take in values from another column, (So if ID_KEL has NA values while ID_KEL…1 has values, we will take from ID_KEL…1 and add them into ID_KEL)\r\n\r\n\r\ndf <- df %>% \r\n  mutate(ID_KEL = coalesce(ID_KEL, ID_KEL...1, ID_KEL...2))\r\n\r\n\r\n\r\nCOMBINE MENNINGGAL TGT AS ONE COLUMN, SINCE SOME OF THE FILES HAVE DIFFERENT LAYOUTS, only 28,29,30,31 is used after checking the dataset earlier on during “df_list”. So only combining those columns\r\n\r\n\r\ndf <- df %>% \r\n  mutate(Meninggal = coalesce(Meninggal, Meninggal...28, Meninggal...29, Meninggal...30, Meninggal...31, Meninggal...26))\r\n\r\n\r\n\r\nTo get only the required columns from the dataframe\r\n\r\n\r\nlibrary(dplyr)\r\n\r\ndf2 <- df %>%\r\n  select(\"MonthYear\", \"ID_KEL\", \"Nama_provinsi\", \"nama_kota\", \"nama_kecamatan\", \"nama_kelurahan\", \"POSITIF\", \"Meninggal\")\r\n\r\n\r\n\r\nAs shown above, we need to clean up the MonthYear column as it is very messy. We will clean up the MonthYear column using Str_replace function, to replace unnecessary characters in the values.\r\n\r\n\r\ndf2 <- df2 %>% \r\n  mutate_at(\"MonthYear\", str_replace, \"data/the1data/COVID-DATA/Standar Kelurahan Data Corona\", \"\")\r\n\r\ndf2 <- df2 %>% \r\n  mutate_at(\"MonthYear\", str_replace, \"[(]\", \"\")\r\n\r\ndf2 <- df2 %>% \r\n  mutate_at(\"MonthYear\", str_replace, \"[)]\", \"\")\r\n\r\ndf2 <- df2 %>% \r\n  mutate_at(\"MonthYear\", str_replace, \".xlsx\", \"\")\r\n\r\n\r\n\r\nTurning MonthYear column into legit date type and removing Date from the MonthYear values (e.g. 2021-02-28 into 2021-02)\r\n\r\n\r\nSys.setlocale(locale=\"ind\")\r\n\r\n\r\n[1] \"LC_COLLATE=Indonesian_Indonesia.1252;LC_CTYPE=Indonesian_Indonesia.1252;LC_MONETARY=Indonesian_Indonesia.1252;LC_NUMERIC=C;LC_TIME=Indonesian_Indonesia.1252\"\r\n\r\ndf2$MonthYear <- c(df2$MonthYear) %>%\r\nas.Date(df2$MonthYear, format =\"%d %B %Y\")\r\n\r\n\r\n\r\nDELETE AWAY WRONG/UNNECESSARY ROWS (NA values in ID_KEL, THE TOTALS, SUBDISTRICT NAME AS ID_KEL ETC)\r\n\r\n\r\ndf2[!is.na(df2$ID_KEL),]\r\n\r\ndf2 <- subset(df2, grepl('^\\\\d+$', df2$ID_KEL))\r\n\r\n\r\n\r\nOrder Dataframe by MonthYear and reset index\r\n\r\n\r\ndf2 <- df2[order(df2$MonthYear),]\r\nfinal_df <- df2\r\nrow.names(final_df) <- 1:nrow(final_df)\r\n\r\n\r\n\r\nWriting out a .rds file from final_df, so as to ensure the data will take up lesser storage space.\r\n\r\n\r\naspatial_df <- write_rds(final_df, \"data/the1data/rds/aspatial_df.rds\")\r\n\r\n\r\n\r\n\r\n\r\naspatial_df <- read_rds(\"data/the1data/rds/aspatial_df.rds\")\r\n\r\n\r\n\r\n3. Importing Geospatial Data\r\nThe following code cunk imports the DKI Jakarta geospatial data into R as a simple feature dataframe.\r\n\r\n\r\ngeospatial_df <- st_read(dsn = \"data/the1data/BATAS DESA DESEMBER 2019 DUKCAPIL DKI JAKARTA\", \r\n                layer = \"BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA\")\r\n\r\n\r\nReading layer `BATAS_DESA_DESEMBER_2019_DUKCAPIL_DKI_JAKARTA' from data source `C:\\teojp3\\IS415_blog\\data\\the1data\\BATAS DESA DESEMBER 2019 DUKCAPIL DKI JAKARTA' \r\n  using driver `ESRI Shapefile'\r\nSimple feature collection with 269 features and 161 fields\r\nGeometry type: MULTIPOLYGON\r\nDimension:     XY\r\nBounding box:  xmin: 106.3831 ymin: -6.370815 xmax: 106.9728 ymax: -5.184322\r\nGeodetic CRS:  WGS 84\r\n\r\nChecking if the CRS is correct or wrong\r\n\r\n\r\nst_crs(geospatial_df)\r\n\r\n\r\nCoordinate Reference System:\r\n  User input: WGS 84 \r\n  wkt:\r\nGEOGCRS[\"WGS 84\",\r\n    DATUM[\"World Geodetic System 1984\",\r\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\r\n            LENGTHUNIT[\"metre\",1]]],\r\n    PRIMEM[\"Greenwich\",0,\r\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\r\n    CS[ellipsoidal,2],\r\n        AXIS[\"latitude\",north,\r\n            ORDER[1],\r\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\r\n        AXIS[\"longitude\",east,\r\n            ORDER[2],\r\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\r\n    ID[\"EPSG\",4326]]\r\n\r\nFrom the above output, we see that the Projected Coordinates System iS WGS84 which is wrong, therefore we’ll Change the Projected Coordinates Systems to DGN95 (which is the national Projeted Coordinates Systems of Indonesia).\r\n\r\n\r\njakarta_DGN95 <- st_transform(geospatial_df, 23845)\r\n\r\n\r\n\r\nOuter Islands are also known as KEPULAUAN SERIBU, we will exclude them as they are detached from the mainland.\r\n\r\n\r\njakarta_DGN95 <- subset(jakarta_DGN95, KAB_KOTA != \"KEPULAUAN SERIBU\")\r\n\r\n\r\n\r\nFor the analysis, we will only keep the first nine fields, whereby the last field is JUMLAH_PEN (Total Population).\r\n\r\n\r\njakarta_DGN95 <- jakarta_DGN95[, 0:9]\r\n\r\n\r\n\r\nCleaning data from jakarta_df, uncovered some inaccuracy between identification keys from aspatial and geospatial after manually checking through their data. If data cleaning is not done, there will be data missing from some states, so the map will have missing values.\r\n\r\n\r\njakarta_DGN95$DESA_KELUR[jakarta_DGN95$DESA == 'BALEKAMBANG'] <- 'BALE KAMBANG'\r\njakarta_DGN95$DESA_KELUR[jakarta_DGN95$DESA == 'HALIM PERDANA KUSUMA'] <- 'HALIM PERDANA KUSUMAH'\r\njakarta_DGN95$DESA_KELUR[jakarta_DGN95$DESA == 'JATIPULO'] <- 'JATI PULO'\r\njakarta_DGN95$DESA_KELUR[jakarta_DGN95$DESA == 'KALIBARU'] <- 'KALI BARU'\r\njakarta_DGN95$DESA_KELUR[jakarta_DGN95$DESA == 'KRAMATJATI'] <- 'KRAMAT JATI'\r\njakarta_DGN95$DESA_KELUR[jakarta_DGN95$DESA == 'PALMERIAM'] <- 'PAL MERIAM'\r\njakarta_DGN95$DESA_KELUR[jakarta_DGN95$DESA == 'PINANGRANTI'] <- 'PINANG RANTI'\r\njakarta_DGN95$DESA_KELUR[jakarta_DGN95$DESA == 'PAL MERAH'] <- 'PALMERAH'\r\njakarta_DGN95$DESA_KELUR[jakarta_DGN95$DESA == 'TENGAH'] <- 'KAMPUNG TENGAH'\r\njakarta_DGN95$DESA_KELUR[jakarta_DGN95$DESA == 'PULOGADUNG'] <- 'PULO GADUNG'\r\njakarta_DGN95$DESA_KELUR[jakarta_DGN95$DESA == 'KALI DERES'] <- 'KALIDERES'\r\njakarta_DGN95$DESA_KELUR[jakarta_DGN95$DESA == 'RAWAJATI'] <- 'RAWA JATI'\r\njakarta_DGN95$DESA_KELUR[jakarta_DGN95$DESA == 'KRENDANG'] <- 'KERENDANG'\r\n\r\n\r\n\r\nFunction to help us check if the identifier keys between the aspatial and geospatial data are correct\r\n\r\n\r\na <-c(aspatial_df$nama_kelurahan)\r\nb <-c(jakarta_DGN95$DESA_KELUR)\r\n\r\na[!(a %in% b)]\r\n\r\n\r\n\r\nWe will drop NA value rows\r\n\r\n\r\njakarta_DGN95 <- jakarta_DGN95 %>% drop_na(OBJECT_ID)\r\n\r\n\r\n\r\nDATA PREPARATION FOR CUML CASE RATE\r\n\r\n\r\nCase_Rate <- aspatial_df %>%\r\n  inner_join(jakarta_DGN95, by=c(\"nama_kelurahan\" = \"DESA_KELUR\")) %>%\r\n  group_by(nama_kelurahan, MonthYear) %>%\r\n  dplyr::summarise(`Covid_Cases_Per_10000_Pop` = (((sum(`POSITIF`)) / (`JUMLAH_PEN`)) / 10000)) %>%\r\n  ungroup() %>%\r\n  pivot_wider(names_from = MonthYear,\r\n              values_from = Covid_Cases_Per_10000_Pop)\r\n\r\n\r\n\r\nDATA PREPARATION FOR CUML DEATH RATE\r\n\r\n\r\nDeath_Rate <- aspatial_df %>%\r\n  inner_join(jakarta_DGN95, by=c(\"nama_kelurahan\" = \"DESA_KELUR\")) %>%\r\n  group_by(nama_kelurahan, MonthYear) %>%\r\n  dplyr::summarise(`Death_Rate_Per_10000` = (sum(Meninggal) / (JUMLAH_PEN / 10000))) %>%\r\n  ungroup() %>%\r\n  pivot_wider(names_from = MonthYear,\r\n              values_from = Death_Rate_Per_10000)\r\n\r\n\r\n\r\nData Preparation for Relative Risk mapping later on\r\n\r\n\r\nPositive_Cases <- aspatial_df %>%\r\n  select('MonthYear', 'nama_kelurahan', 'POSITIF', 'Meninggal')\r\n\r\n\r\n\r\n\r\n\r\nPositive_Cases <- Positive_Cases[Positive_Cases$MonthYear == \"2021-07-31\",]\r\n\r\n\r\n\r\n\r\n\r\nDeath_Rate <- left_join(Positive_Cases, Death_Rate, by= c(\"nama_kelurahan\" = \"nama_kelurahan\"))\r\n\r\nDeath_Rate <- subset(Death_Rate, select = -c(MonthYear))\r\n\r\n\r\n\r\nRenaming of Columns\r\n\r\n\r\ncolnames(Case_Rate) <- c('SUB_DISTRICT', '03-2020', '04-2020', '05-2020', '06-2020', '07-2020', '08-2020', '09-2020', '10-2020', '11-2020', '12-2020', '01-2021', '02-2021', '03-2021', '04-2021', '05-2021', '06-2021', '07-2021')\r\n\r\ncolnames(Death_Rate) <- c('SUB_DISTRICT', 'POSITIVE_CASES', 'DEATHS', '03-2020', '04-2020', '05-2020', '06-2020', '07-2020', '08-2020', '09-2020', '10-2020', '11-2020', '12-2020', '01-2021', '02-2021', '03-2021', '04-2021', '05-2021', '06-2021', '07-2021')\r\n\r\n\r\n\r\nQuick check to ensure there are no NA values\r\n\r\n\r\nCase_Rate[rowSums(is.na(Case_Rate))!=0,]\r\n\r\n\r\n\r\nDeath_Rate has NA rows, deleted them using na.omit() function\r\n\r\n\r\nDeath_Rate[rowSums(is.na(Death_Rate))!=0,]\r\n\r\nDeath_Rate <- na.omit(Death_Rate)\r\n\r\n\r\n\r\nUsing rds files instead\r\n\r\n\r\nCase_Rate_rds <- write_rds(Case_Rate, \"data/the1data/rds/Case_Rate_rds.rds\")\r\nDeath_Rate_rds <- write_rds(Death_Rate, \"data/the1data/rds/Death_Rate_rds.rds\")\r\n\r\n\r\n\r\n\r\n\r\nCase_Rate_rds <- read_rds(\"data/the1data/rds/Case_Rate_rds.rds\")\r\nDeath_Rate_rds <- read_rds(\"data/the1data/rds/Death_Rate_rds.rds\")\r\n\r\n\r\n\r\nGEOSPATIAL ANALYSIS\r\nGeorelational join (Geospatial data with Aspatial data)\r\n\r\n\r\nCase_Rate_Final <- left_join(jakarta_DGN95, Case_Rate_rds, by= c(\"DESA_KELUR\" = \"SUB_DISTRICT\"))\r\n\r\n\r\n\r\n\r\n\r\nDeath_Rate_Final <- left_join(jakarta_DGN95, Death_Rate_rds, by= c(\"DESA_KELUR\" = \"SUB_DISTRICT\"))\r\n\r\nDeath_Rate_Final[rowSums(is.na(Death_Rate_Final))!=0,]\r\n\r\n\r\nSimple feature collection with 0 features and 28 fields\r\nBounding box:  xmin: NA ymin: NA xmax: NA ymax: NA\r\nProjected CRS: DGN95 / Indonesia TM-3 zone 54.1\r\n [1] OBJECT_ID      KODE_DESA      DESA           KODE          \r\n [5] PROVINSI       KAB_KOTA       KECAMATAN      DESA_KELUR    \r\n [9] JUMLAH_PEN     POSITIVE_CASES DEATHS         03-2020       \r\n[13] 04-2020        05-2020        06-2020        07-2020       \r\n[17] 08-2020        09-2020        10-2020        11-2020       \r\n[21] 12-2020        01-2021        02-2021        03-2021       \r\n[25] 04-2021        05-2021        06-2021        07-2021       \r\n[29] geometry      \r\n<0 rows> (or 0-length row.names)\r\n\r\nGEOSPATIAL MAPPING\r\n\r\n\r\nsummary(Case_Rate_Final$`03-2020`)\r\n\r\n\r\n          Min.        1st Qu.         Median           Mean \r\n0.000000000000 0.000000000000 0.000000003264 0.000000007609 \r\n       3rd Qu.           Max. \r\n0.000000006928 0.000000498826 \r\n\r\nPlotting multiple small choropleth maps (KAB = District Level, Kota = Subdistrict). So March 2020 is the first month that we have data on. From the plotted map, we can see that there is an even distribution throughout the different districts (no particular district with outlandish number of cases)\r\n\r\n\r\ntm_shape(Case_Rate_Final) +\r\n  tm_fill(\"03-2020\",\r\n          style = 'quantile',\r\n          palette = \"Blues\",\r\n          thres.poly = 0) + \r\n  tm_facets(by=\"KAB_KOTA\", \r\n            free.coords=TRUE, \r\n            drop.shapes=TRUE) +\r\n  tm_layout(legend.show = TRUE,\r\n            main.title = 'Distribution of cumulative confirmed cases\\nrate per 10,000 Population (March 2020)',\r\n            main.title.position = \"centre\", \r\n            title.size = 12) +\r\n  tm_borders(alpha = 0.5)\r\n\r\n\r\n\r\n\r\n\r\n\r\nsummary(Death_Rate_Final$`03-2020`)\r\n\r\n\r\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \r\n0.00000 0.00000 0.00000 0.08094 0.00000 3.05344 \r\n\r\n\r\n\r\ntm_shape(Death_Rate_Final) +\r\n  tm_fill(\"03-2020\",\r\n          style = \"jenks\",\r\n          palette = \"Blues\",\r\n          thres.poly = 0) + \r\n  tm_facets(by=\"KAB_KOTA\", \r\n            free.coords=TRUE, \r\n            drop.shapes=TRUE) +\r\n  tm_layout(legend.show = TRUE,\r\n            main.title = 'Distribution of cumulative death rate\\nper 10,000 Population (March 2020)',\r\n            main.title.position = \"centre\", \r\n            title.size = 12) +\r\n  tm_borders(alpha = 0.5)\r\n\r\n\r\n\r\n\r\nNORMAL MAINLAND MAP\r\n\r\n\r\ntm_shape(Case_Rate_Final)+\r\n  tm_fill(\"07-2021\", \r\n          style = \"quantile\", \r\n          palette = \"Blues\",\r\n          title = \"Cumulative Case Rate\") +\r\n  tm_layout(main.title = \"Cumulative Confirmed Case Rate in July 2021\",\r\n            main.title.position = \"center\",\r\n            main.title.size = 1.2,\r\n            legend.outside = TRUE,\r\n            legend.height = 0.45, \r\n            legend.width = 0.35,\r\n            frame = TRUE) +\r\n  tm_borders(alpha = 0.5) +\r\n  tm_compass(type=\"8star\", size = 2, position = c( 'left','bottom')) +\r\n  tm_scale_bar(position = c( 'left','bottom')) +\r\n  tm_grid(alpha =0.2) \r\n\r\n\r\n\r\n\r\nTO PLOT MAPS SIDE BY SIDE FOR COMPARISON\r\n\r\n\r\ntm_shape(Case_Rate_Final)+ \r\n  tm_polygons(c(\"03-2020\",\"07-2021\"),\r\n          style = \"quantile\", \r\n          palette = \"Blues\") +\r\n  tm_layout(legend.position = c(\"left\", \"bottom\"))\r\n\r\n\r\n\r\n\r\nTHEMATIC MAPPING\r\nPERCENTILE MAP????\r\n\r\n\r\npercent <- c(0,.01,.1,.5,.9,.99,1)\r\nvar <- Case_Rate_Final[\"07-2021\"] %>%\r\n  st_set_geometry(NULL)\r\nquantile(var[,1], percent)\r\n\r\n\r\n            0%             1%            10%            50% \r\n0.000001873189 0.000002862999 0.000004581759 0.000006583395 \r\n           90%            99%           100% \r\n0.000009396568 0.000019660003 0.000038082902 \r\n\r\n\r\n\r\nget.var <- function(vname,df) {\r\n  v <- df[vname] %>% \r\n    st_set_geometry(NULL)\r\n  v <- unname(v[,1])\r\n  return(v)\r\n}\r\n\r\n\r\n\r\n\r\n\r\npercent <- c(0,.01,.1,.5,.9,.99,1)\r\nvar <- get.var(\"07-2021\", Case_Rate_Final)\r\nbperc <- quantile(var,percent)\r\ntm_shape(jakarta_DGN95) +\r\n  tm_polygons() +\r\ntm_shape(Case_Rate_Final) +\r\n  tm_fill(\"07-2021\",\r\n          title=\"07-2021\",\r\n          breaks=bperc,\r\n          palette=\"Blues\",\r\n          labels=c(\"< 1%\", \"1% - 10%\",\r\n                   \"10% - 50%\", \r\n                   \"50% - 90%\",\r\n                   \"90% - 99%\", \r\n                   \"> 99%\"))  +\r\n  tm_borders() +\r\n  tm_layout(title = \"Percentile Map\", \r\n            title.position = c(\"right\",\r\n                               \"bottom\"))\r\n\r\n\r\n\r\n\r\n\r\n\r\npercentmap <- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\r\n  percent <- c(0,.01,.1,.5,.9,.99,1)\r\n  var <- get.var(vnam,df)\r\n  bperc <- quantile(var,percent)\r\n  tm_shape(jakarta_DGN95) +\r\n  tm_polygons() +\r\n  tm_shape(df) +\r\n     tm_fill(vnam,\r\n             title=legtitle,\r\n             breaks=bperc,\r\n             palette=\"Blues\",\r\n          labels=c(\"< 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"> 99%\"))  +\r\n  tm_borders() +\r\n  tm_layout(main.title = \"Cumulative Confirmed Case Rate in July 2021\",\r\n            main.title.position = \"center\",\r\n            main.title.size = 1.2,\r\n            legend.outside = TRUE,\r\n            legend.height = 0.45, \r\n            legend.width = 0.35,\r\n            frame = TRUE) +\r\n  tm_compass(type=\"8star\", size = 2, position = c( 'left','bottom')) +\r\n  tm_scale_bar(position = c( 'left','bottom'))\r\n}\r\n\r\n\r\n\r\n\r\n\r\nCR_July2021_percentmap <- percentmap(\"07-2021\", Case_Rate_Final)\r\nCR_March2020_percentmap <- percentmap(\"03-2020\", Case_Rate_Final)\r\n\r\n\r\n\r\n\r\n\r\nCR_March2020_percentmap\r\n\r\n\r\n\r\n\r\nBOXBREAKS BOX MAP????\r\n\r\n\r\nboxbreaks <- function(v,mult=1.5) {\r\n  qv <- unname(quantile(v))\r\n  iqr <- qv[4] - qv[2]\r\n  upfence <- qv[4] + mult * iqr\r\n  lofence <- qv[2] - mult * iqr\r\n  # initialize break points vector\r\n  bb <- vector(mode=\"numeric\",length=7)\r\n  # logic for lower and upper fences\r\n  if (lofence < qv[1]) {  # no lower outliers\r\n    bb[1] <- lofence\r\n    bb[2] <- floor(qv[1])\r\n  } else {\r\n    bb[2] <- lofence\r\n    bb[1] <- qv[1]\r\n  }\r\n  if (upfence > qv[5]) { # no upper outliers\r\n    bb[7] <- upfence\r\n    bb[6] <- ceiling(qv[5])\r\n  } else {\r\n    bb[6] <- upfence\r\n    bb[7] <- qv[5]\r\n  }\r\n  bb[3:5] <- qv[2:4]\r\n  return(bb)\r\n}\r\n\r\n\r\n\r\n\r\n\r\nget.var <- function(vname,df) {\r\n  v <- df[vname] %>% st_set_geometry(NULL)\r\n  v <- unname(v[,1])\r\n  return(v)\r\n}\r\n\r\n\r\n\r\n\r\n\r\nJuly2021_No_Zero <- Case_Rate_Final %>%\r\n  filter('07-2021' >= 0)\r\nvar <- get.var(\"07-2021\", Case_Rate_Final)  \r\nboxbreaks(var)\r\n\r\n\r\n[1] 0.000001873189 0.000001933497 0.000005451432 0.000006583395\r\n[5] 0.000007796722 0.000011314658 0.000038082902\r\n\r\n\r\n\r\nboxmap <- function(vnam, df, \r\n                   legtitle=NA,\r\n                   mtitle=\"Box Map\",\r\n                   mult=1.5){\r\n  var <- get.var(vnam,df)\r\n  bb <- boxbreaks(var)\r\n  tm_shape(df) +\r\n     tm_fill(vnam,title=legtitle,\r\n             breaks=bb,\r\n             palette=\"Blues\",\r\n          labels = c(\"lower outlier\", \r\n                     \"< 25%\", \r\n                     \"25% - 50%\", \r\n                     \"50% - 75%\",\r\n                     \"> 75%\", \r\n                     \"upper outlier\"))  +\r\n  tm_borders() +\r\n  tm_layout(main.title = \"Cumulative Confirmed Case Rate in July 2021\",\r\n            main.title.position = \"center\",\r\n            main.title.size = 1.2,\r\n            legend.outside = TRUE,\r\n            legend.height = 0.45, \r\n            legend.width = 0.35,\r\n            frame = TRUE) +\r\n  tm_compass(type=\"8star\", size = 2, position = c( 'left','bottom')) +\r\n  tm_scale_bar(position = c( 'left','bottom'))\r\n}\r\n\r\n\r\n\r\n\r\n\r\nboxmap(\"07-2021\", Case_Rate_Final)\r\n\r\n\r\n\r\n\r\nRelative Risk\r\n\r\n\r\nDeath_Rate_Final <- Death_Rate_Final %>%\r\n  mutate(`EXPECTED_DEATH` = `POSITIVE_CASES` * `07-2021`)\r\n\r\nDeath_Rate_Final <- Death_Rate_Final %>%\r\n  mutate(`SMR` = `DEATHS` / `EXPECTED_DEATH`)\r\n\r\n\r\n\r\nData Prepartion for Relative Risk Mapping\r\n\r\n\r\n# \r\n# Jakarta_Death_Final   <- Jakarta_Death_Final %>%  group_by('Expected_Death',Sub_District)  %>% dplyr::summarise(`SMR` = (Death)/(Expected_Death)) %>% ungroup()\r\n# \r\n# Jakarta_Death_Final   <- Jakarta_Death_Final %>%  group_by(Sub_District,SMR)  %>% dplyr::summarise(`SMR_Avg` = sum(SMR)/15)\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-09-06T17:59:39+08:00"
    }
  ],
  "collections": ["posts/posts.json"]
}
